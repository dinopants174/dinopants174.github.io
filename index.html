<!DOCTYPE html>
<html>
	<head>
		<link type="text/css" rel="stylesheet" href="stylesheet.css"/>
		<link rel="shortcut icon" href="img/favicon.ico" >
		<link type="text/css" rel="stylesheet" media="screen and (max-width: 980px)" href="smaller.css"/>
		<link type="text/css" rel="stylesheet" media="screen and (max-width: 680px)" href="still_smaller.css"/>
		<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
		<script language="javascript" type="text/javascript" src="scroll.js"></script>
		<script language="javascript" type="text/javascript">
			 function f_in(which_im){
			 	document.getElementById('fade').style.display = 'block';
			 	which_im.style.display = 'block';
			 }

			function f_out(){
				document.getElementById('fade').style.display = 'none';
				var elems = document.getElementsByClassName('im_info');
				for (var i=0; i < elems.length; i++){
					elems[i].style.display = 'none';
				}
			}
		</script>
		<title>Zoher Ghadyali</title>
	</head>

	<body>
		<a onclick="f_out()"><div id="fade"></div></a>
		<div id="pagewrap">
			<div id="NavBar_Bottom">
			</div>
			<ul id="NavBar_Top">
				<li><a href="#port_bg">portfolio</a></li>
				<li><a href="#ABOUTME">about me</a></li>
				<li id="NBar_Name">ZOHER GHADYALI</li>
				<li><a href="https://www.dropbox.com/s/e2nui1xak29jue1/Olin%20Resume%20v2.docx" target="_blank">resume</a></li>
				<li><a href="#CONTACT">contact</a></li>
			</ul>

			<img id="Cover_Image" src="img/cover_im_2.png">

			<ul id="SMIcons">
				<li><a href="mailto:zoher.ghadyali@students.olin.edu" target="_top"><img id="cust_mail" class="SM_im" src="img/sm_mail.png"></a></li>
				<li><a href="https://www.facebook.com/zoher.ghadyali" target="_blank"><img class="SM_im" src="img/sm_facebook.png"></a></li>
				<li><a href="http://www.linkedin.com/pub/zoher-ghadyali/84/19a/630" target="_blank"><img class="SM_im" src="img/sm_linkedin.png"></a></li>
				<li><a href="https://twitter.com/dinopants174" target="_blank"><img class="SM_im" src="img/sm_twitter.png"></a></li>
				<li><a href="https://github.com/dinopants174" target="_blank"><img class="SM_im" src="img/sm_github.png"></a></li>
			</ul>
			<div id="port_bg">
				<img id="PORTFOLIO" src="img/portfolio_title.png">
				<div id="Blank_1"></div>
 				<a onclick="f_in(im_1_info)"><img class="portfolio_images" src="img/portfolio/im_1.png"></a>
				<div class="im_info" id="im_1_info">
    				<h2 class="title">SmarterBoard</h2>
    				<ul id="ExpIcons">
    					<li><img class="exp_logo" src="img/py_logo.png"></li>
    				</ul>
    				<img id="SmBrd_1" src="img/port_info/SmBrd_1.png">
    				<img id="SmBrd_2" src="img/port_info/SmBrd_2.png">
    				<p>In my second semester, I designed and built a program that would take an image of a hand drawn circuit diagram and render it neatly and professionally for use in a lab report or presentation.</p>

    				<p>My group chose this project after realizing that we could essentially automate the conversions we, as students, were doing, using services like Fritzing or LT Spice, to make hand-drawn circuit diagrams appropriate for our lab reports and presentations.</p>
    				<img id="SmBrd_3" src="img/port_info/SmBrd_3.png">
    				<p>Above is the general pipeline we designed for our service. Our program took the input image in and converted it to black and white, and then to a matrix. We found the central lines of the diagram by looking at where the average darkness was greatest in the rows and columns of the matrix and cropped around segments of the diagram by finding intersections between these central lines.</p>
    				<p>Having isolated each segment, we searched each image for components by looking for any instance of non-white space above and below the central line of each segment. Once we found these instances, we were able to crop to the components within the segment by making an assumption above the maximum distance between each instance. We passed these into a machine learning classifier.</p>
    				<img id="SmBrd_4" src="img/port_info/SmBrd_4.png">
    				<p>Using 526 images of hand-drawn resistors and capacitors, in addition to a slanted Gabor filter, our machine learning classifier was able to identify components as either a resistor or a capacitor. Once we identified which components were in each segment, we drew each segment and reassembled the drawing, now appropriate for a lab report or presentation.</p>
    				<p>For more information about our work, please check out our <a href="https://github.com/dinopants174/SmarterBoard" target="_blank">GitHub repository</a>.</p>
				</div>

				<a onclick="f_in(im_2_info)">
 					<img class="portfolio_images" src="img/portfolio/im_3.png">
 				</a>
 				<div class="im_info" id="im_2_info">
 					<h2 class="title">Team Sailing Research</h2>
 					<ul id="ExpIcons">
    					<li><img class="exp_logo" src="img/py_logo.png"></li>
    					<li><img class="exp_logo" src="img/rpi_logo.png"></li>
    					<li><img class="exp_logo" src="img/ard_logo.png"></li>
    				</ul>
 					<img id="TS_1" src="img/port_info/Team_Sailing_1.jpg">
 					<p>In the summer of 2014, I worked on Olin's campus as part of the Team Sailing Research team, with Research Scientist Alex Morrow. Our goal was to begin prototyping a system that would increase the autonomy of blind sailors on sailboats. By the end of the summer, we had succeeded in building a platform that took a blind sailor's input in the form of a key-press on a standard 12 button keypad. Each key-press corresponded to a certain piece of information that a Raspberry Pi computer would say aloud to the blind sailor.</p>
 					<img id="TS_2" src="img/port_info/TS_2_v2.png">
 					<p>Above are two schematics detailing the current interactions of blind sailors and the way our system works in this context. Currently, two blind sailors sail with two sighted guides. The guides are using their vision to relay information to the blind sailors. Our system performs the same action but eliminates the middleman in the current system. The blind sailor only gets the information they requested from each key-press.</p>
 					<img id="TS_3" src="img/port_info/TS_3.png">
 					<p>The key-presses on our 12 button keypad were read and interpreted by an Arduino Uno, a microprocesser we used due to its easy prototyping capabilities and affordability. Once the Arduino Uno understood which key had been pressed, it communicated that over radio to a credit-card sized computer, the Raspberry Pi.</p>
 					<p>The Raspbeery Pi is constantly gathering data and, when it understands which key has been pressed, it performs a text-to-speech conversion. It reads the text file of whatever information that key corresponds to, converts it to an audio file, and recites the information aloud to the blind sailor.</p>
 					<p>For more information about this ongoing project, please contact <a href="http://www.olin.edu/faculty/profile/alexander-morrow/" target="_blank">Alex Morrow</a>.</p>
 				</div>
 				<img class="portfolio_images" src="img/portfolio/im_2.png">
 				<img class="portfolio_images" src="img/portfolio/im_9.png">
 				<img class="portfolio_images" src="img/portfolio/im_4.png">
 				<img class="portfolio_images" src="img/portfolio/im_7.png">
 				<img class="portfolio_images" src="img/portfolio/im_5.png">
 				<img class="portfolio_images" src="img/portfolio/im_10.png">
 				<img class="portfolio_images" src="img/portfolio/im_8.png">
 				<img class="portfolio_images" src="img/portfolio/im_6.png">
 				<img class="portfolio_images" src="img/portfolio/im_11.png">
 			</div>
		</div>
	</body>
</html>